{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score, precision_recall_curve, average_precision_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quadro M1000M'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = \"cuda\"\n",
    "    print(\"cuda available\")\n",
    "torch.cuda.get_device_name(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = pd.read_csv('train.csv.zip')\n",
    "df_test = pd.read_csv('test.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [col for col in df_train.columns if col not in ['ID_code', 'target']]\n",
    "y_train = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "rs = RobustScaler() \n",
    "df_train[train_cols] = ss.fit_transform(df_train[train_cols])\n",
    "df_test[train_cols] = ss.fit_transform(df_test[train_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.577102</td>\n",
       "      <td>-1.273737</td>\n",
       "      <td>0.451707</td>\n",
       "      <td>-0.833709</td>\n",
       "      <td>0.235571</td>\n",
       "      <td>-0.536430</td>\n",
       "      <td>-0.334926</td>\n",
       "      <td>0.608751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263374</td>\n",
       "      <td>-1.149158</td>\n",
       "      <td>0.817469</td>\n",
       "      <td>-0.411013</td>\n",
       "      <td>0.168705</td>\n",
       "      <td>-1.578117</td>\n",
       "      <td>1.022131</td>\n",
       "      <td>-0.373968</td>\n",
       "      <td>-1.026398</td>\n",
       "      <td>0.214135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.269959</td>\n",
       "      <td>-0.622138</td>\n",
       "      <td>1.190360</td>\n",
       "      <td>-0.688846</td>\n",
       "      <td>0.790975</td>\n",
       "      <td>1.539900</td>\n",
       "      <td>0.244461</td>\n",
       "      <td>-0.003525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966611</td>\n",
       "      <td>0.093605</td>\n",
       "      <td>0.443623</td>\n",
       "      <td>1.908764</td>\n",
       "      <td>-0.817594</td>\n",
       "      <td>1.522342</td>\n",
       "      <td>1.067654</td>\n",
       "      <td>-0.129400</td>\n",
       "      <td>0.825417</td>\n",
       "      <td>0.505685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.681113</td>\n",
       "      <td>-0.276066</td>\n",
       "      <td>0.516988</td>\n",
       "      <td>0.536516</td>\n",
       "      <td>-0.305477</td>\n",
       "      <td>-0.511033</td>\n",
       "      <td>1.769839</td>\n",
       "      <td>-0.564749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072093</td>\n",
       "      <td>0.777997</td>\n",
       "      <td>-0.174131</td>\n",
       "      <td>-0.412316</td>\n",
       "      <td>1.151591</td>\n",
       "      <td>2.297370</td>\n",
       "      <td>-1.617906</td>\n",
       "      <td>-0.695141</td>\n",
       "      <td>-0.381449</td>\n",
       "      <td>0.356681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125158</td>\n",
       "      <td>-0.129426</td>\n",
       "      <td>-0.667575</td>\n",
       "      <td>0.195355</td>\n",
       "      <td>0.927992</td>\n",
       "      <td>0.410672</td>\n",
       "      <td>0.500633</td>\n",
       "      <td>-0.474201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270216</td>\n",
       "      <td>-0.891456</td>\n",
       "      <td>-0.818468</td>\n",
       "      <td>-0.478548</td>\n",
       "      <td>1.607869</td>\n",
       "      <td>-0.789517</td>\n",
       "      <td>-0.959020</td>\n",
       "      <td>1.501744</td>\n",
       "      <td>0.697118</td>\n",
       "      <td>-0.543502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.277303</td>\n",
       "      <td>0.035610</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>-0.077829</td>\n",
       "      <td>0.738607</td>\n",
       "      <td>0.955574</td>\n",
       "      <td>0.613372</td>\n",
       "      <td>0.791544</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.036191</td>\n",
       "      <td>0.688988</td>\n",
       "      <td>-1.405987</td>\n",
       "      <td>1.468536</td>\n",
       "      <td>-1.501101</td>\n",
       "      <td>-0.958473</td>\n",
       "      <td>0.297627</td>\n",
       "      <td>0.645537</td>\n",
       "      <td>0.706318</td>\n",
       "      <td>-0.525375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target     var_0     var_1     var_2     var_3     var_4  \\\n",
       "0  train_0       0 -0.577102 -1.273737  0.451707 -0.833709  0.235571   \n",
       "1  train_1       0  0.269959 -0.622138  1.190360 -0.688846  0.790975   \n",
       "2  train_2       0 -0.681113 -0.276066  0.516988  0.536516 -0.305477   \n",
       "3  train_3       0  0.125158 -0.129426 -0.667575  0.195355  0.927992   \n",
       "4  train_4       0 -0.277303  0.035610  0.817683 -0.077829  0.738607   \n",
       "\n",
       "      var_5     var_6     var_7    ...      var_190   var_191   var_192  \\\n",
       "0 -0.536430 -0.334926  0.608751    ...     0.263374 -1.149158  0.817469   \n",
       "1  1.539900  0.244461 -0.003525    ...     0.966611  0.093605  0.443623   \n",
       "2 -0.511033  1.769839 -0.564749    ...    -0.072093  0.777997 -0.174131   \n",
       "3  0.410672  0.500633 -0.474201    ...     0.270216 -0.891456 -0.818468   \n",
       "4  0.955574  0.613372  0.791544    ...    -1.036191  0.688988 -1.405987   \n",
       "\n",
       "    var_193   var_194   var_195   var_196   var_197   var_198   var_199  \n",
       "0 -0.411013  0.168705 -1.578117  1.022131 -0.373968 -1.026398  0.214135  \n",
       "1  1.908764 -0.817594  1.522342  1.067654 -0.129400  0.825417  0.505685  \n",
       "2 -0.412316  1.151591  2.297370 -1.617906 -0.695141 -0.381449  0.356681  \n",
       "3 -0.478548  1.607869 -0.789517 -0.959020  1.501744  0.697118 -0.543502  \n",
       "4  1.468536 -1.501101 -0.958473  0.297627  0.645537  0.706318 -0.525375  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, dropout = 0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(200, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = classifier(100)\n",
    "print(model)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "train_x = torch.from_numpy(df_train[train_cols].values).float().cuda()\n",
    "train_y = torch.from_numpy(y_train.values).float().cuda()\n",
    "\n",
    "test_x = torch.from_numpy(df_test[train_cols].values).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "# te_x_dataset = torch.utils.data.TensorDataset(te_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_x_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = classifier(100)\n",
    "model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.005)\n",
    "# criterion = nn.CrossEntropyLoss() # also number of outputs should be 2\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2651, -0.0782, -0.6425,  ...,  1.0954,  1.4456, -1.4608],\n",
       "        [-0.2241, -0.4485, -0.9721,  ...,  0.1203, -0.8118, -1.2728],\n",
       "        [ 0.9425,  0.3757, -0.2364,  ...,  0.0755, -0.1102,  0.4335],\n",
       "        ...,\n",
       "        [-0.3833, -1.3038,  0.6323,  ..., -0.1134,  0.7703,  1.1388],\n",
       "        [-1.3360, -0.8418,  0.6823,  ...,  0.0901, -0.5293,  1.5723],\n",
       "        [ 0.9403,  0.9838,  1.2544,  ..., -0.3421, -0.8356,  1.4559]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 200]),\n",
       " torch.Size([1000, 1, 200]),\n",
       " torch.Size([1000]),\n",
       " torch.Size([1000, 1]))"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x.view(x.shape[0],1,-1).shape, y.shape, y.view(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7336, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = model(x)\n",
    "l = criterion(o, y.view(-1,1))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49123233556747437\n",
      "0.4669589400291443\n",
      "[12.237966537475586, 11.555702209472656]\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "train_losses, test_losses = [],[]\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for step, (x_batch,y_batch) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "#         print(step)\n",
    "#         print(x_batch)\n",
    "#         print(y_batch)\n",
    "        \n",
    "        model.train()\n",
    "        output = model(x_batch)\n",
    "        loss = criterion(output, y_batch.view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        \n",
    "        if step % 100 ==0:\n",
    "            print(running_loss.item())\n",
    "        \n",
    "    train_losses.append(running_loss.item())    \n",
    "\n",
    "print(train_losses)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 1])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    pred_y = model(test_x)\n",
    "    print(pred_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2346],\n",
       "        [-0.2744],\n",
       "        [-0.4884],\n",
       "        ...,\n",
       "        [-0.3405],\n",
       "        [-0.3741],\n",
       "        [-0.3689]], device='cuda:0')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = pred_y.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.23459193, -0.27436283, -0.4884416 , ..., -0.34051102,\n",
       "       -0.3740533 , -0.36889756], dtype=float32)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "sigmoid(pred_y).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = pred_y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.69203746, -0.036253992)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(pred_y), max(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61048   , 0.41939977, 0.5215119 , ..., 0.24173193, 0.64389914,\n",
       "       0.27249616], dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_y-min(pred_y))/(max(pred_y)-min(pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN with kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits = 5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (159999,) (40001,)\n",
      "1 (159999,) (40001,)\n",
      "2 (160000,) (40000,)\n",
      "3 (160001,) (39999,)\n",
      "4 (160001,) (39999,)\n"
     ]
    }
   ],
   "source": [
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(df_train, y_train)):\n",
    "    print(n_fold, train_idx.shape, val_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number:  1\n",
      "Epoch: 1   Training loss: 0.268434   Validation Loss: 0.245510    Val_auc:0.84178\n",
      "Validation loss decresed from inf ----> 0.245510 Saving Model\n",
      "Epoch: 2   Training loss: 0.247812   Validation Loss: 0.243120    Val_auc:0.84311\n",
      "Validation loss decresed from 0.245510 ----> 0.243120 Saving Model\n",
      "Epoch: 3   Training loss: 0.241099   Validation Loss: 0.240043    Val_auc:0.84357\n",
      "Validation loss decresed from 0.243120 ----> 0.240043 Saving Model\n",
      "Epoch: 4   Training loss: 0.237372   Validation Loss: 0.239314    Val_auc:0.84441\n",
      "Validation loss decresed from 0.240043 ----> 0.239314 Saving Model\n",
      "Epoch: 5   Training loss: 0.234464   Validation Loss: 0.238801    Val_auc:0.84421\n",
      "Validation loss decresed from 0.239314 ----> 0.238801 Saving Model\n",
      "Epoch: 6   Training loss: 0.231283   Validation Loss: 0.241705    Val_auc:0.84438\n",
      "Epoch: 7   Training loss: 0.229159   Validation Loss: 0.240279    Val_auc:0.84383\n",
      "Epoch: 8   Training loss: 0.227509   Validation Loss: 0.240172    Val_auc:0.84430\n",
      "Epoch: 9   Training loss: 0.226232   Validation Loss: 0.240551    Val_auc:0.84331\n",
      "Epoch: 10   Training loss: 0.224967   Validation Loss: 0.243024    Val_auc:0.84391\n",
      "Epoch: 11   Training loss: 0.223575   Validation Loss: 0.244590    Val_auc:0.84193\n",
      "Epoch: 12   Training loss: 0.222715   Validation Loss: 0.243531    Val_auc:0.84150\n",
      "Epoch: 13   Training loss: 0.220320   Validation Loss: 0.242965    Val_auc:0.84283\n",
      "Epoch: 14   Training loss: 0.219463   Validation Loss: 0.245945    Val_auc:0.84114\n",
      "Epoch: 15   Training loss: 0.218198   Validation Loss: 0.244979    Val_auc:0.84179\n",
      "Epoch: 16   Training loss: 0.217764   Validation Loss: 0.245584    Val_auc:0.84074\n",
      "Epoch: 17   Training loss: 0.216470   Validation Loss: 0.249159    Val_auc:0.84141\n",
      "Epoch: 18   Training loss: 0.215163   Validation Loss: 0.251899    Val_auc:0.84143\n",
      "Epoch: 19   Training loss: 0.214255   Validation Loss: 0.247673    Val_auc:0.83785\n",
      "Epoch: 20   Training loss: 0.213341   Validation Loss: 0.247521    Val_auc:0.84058\n",
      "Epoch: 21   Training loss: 0.212762   Validation Loss: 0.247252    Val_auc:0.83892\n",
      "Epoch: 22   Training loss: 0.211238   Validation Loss: 0.249863    Val_auc:0.84083\n",
      "Epoch: 23   Training loss: 0.210785   Validation Loss: 0.252874    Val_auc:0.84008\n",
      "Epoch: 24   Training loss: 0.210050   Validation Loss: 0.250074    Val_auc:0.83825\n",
      "Epoch: 25   Training loss: 0.209474   Validation Loss: 0.249448    Val_auc:0.83717\n",
      "Epoch: 26   Training loss: 0.208330   Validation Loss: 0.250601    Val_auc:0.83605\n",
      "Epoch: 27   Training loss: 0.207031   Validation Loss: 0.250553    Val_auc:0.83637\n",
      "Epoch: 28   Training loss: 0.206151   Validation Loss: 0.253094    Val_auc:0.83531\n",
      "Epoch: 29   Training loss: 0.206228   Validation Loss: 0.254128    Val_auc:0.83434\n",
      "Epoch: 30   Training loss: 0.205510   Validation Loss: 0.252193    Val_auc:0.83518\n",
      "Fold 1 metrics:   Avg Training loss: 0.2212   Avg Validation Loss: 0.2462   Val_auc:0.83518\n",
      "Saving test results for best model\n",
      "end of fold:  1 \n",
      "\n",
      "Fold number:  2\n",
      "Epoch: 1   Training loss: 0.267595   Validation Loss: 0.245267    Val_auc:0.84386\n",
      "Validation loss decresed from inf ----> 0.245267 Saving Model\n",
      "Epoch: 2   Training loss: 0.245765   Validation Loss: 0.242567    Val_auc:0.84383\n",
      "Validation loss decresed from 0.245267 ----> 0.242567 Saving Model\n",
      "Epoch: 3   Training loss: 0.240151   Validation Loss: 0.240776    Val_auc:0.84523\n",
      "Validation loss decresed from 0.242567 ----> 0.240776 Saving Model\n",
      "Epoch: 4   Training loss: 0.236230   Validation Loss: 0.243032    Val_auc:0.84435\n",
      "Epoch: 5   Training loss: 0.233808   Validation Loss: 0.240189    Val_auc:0.84512\n",
      "Validation loss decresed from 0.240776 ----> 0.240189 Saving Model\n",
      "Epoch: 6   Training loss: 0.231366   Validation Loss: 0.239807    Val_auc:0.84440\n",
      "Validation loss decresed from 0.240189 ----> 0.239807 Saving Model\n",
      "Epoch: 7   Training loss: 0.229387   Validation Loss: 0.240244    Val_auc:0.84517\n",
      "Epoch: 8   Training loss: 0.227242   Validation Loss: 0.242484    Val_auc:0.84366\n",
      "Epoch: 9   Training loss: 0.225834   Validation Loss: 0.243735    Val_auc:0.84279\n",
      "Epoch: 10   Training loss: 0.224541   Validation Loss: 0.242246    Val_auc:0.84295\n",
      "Epoch: 11   Training loss: 0.222294   Validation Loss: 0.243530    Val_auc:0.84279\n",
      "Epoch: 12   Training loss: 0.221988   Validation Loss: 0.243234    Val_auc:0.84219\n",
      "Epoch: 13   Training loss: 0.220270   Validation Loss: 0.244988    Val_auc:0.84254\n",
      "Epoch: 14   Training loss: 0.219257   Validation Loss: 0.245212    Val_auc:0.83994\n",
      "Epoch: 15   Training loss: 0.217919   Validation Loss: 0.244432    Val_auc:0.84099\n",
      "Epoch: 16   Training loss: 0.215854   Validation Loss: 0.245033    Val_auc:0.84148\n",
      "Epoch: 17   Training loss: 0.214532   Validation Loss: 0.247266    Val_auc:0.83965\n",
      "Epoch: 18   Training loss: 0.215296   Validation Loss: 0.248289    Val_auc:0.83895\n",
      "Epoch: 19   Training loss: 0.213933   Validation Loss: 0.248782    Val_auc:0.83649\n",
      "Epoch: 20   Training loss: 0.212405   Validation Loss: 0.247455    Val_auc:0.83827\n",
      "Epoch: 21   Training loss: 0.211717   Validation Loss: 0.247714    Val_auc:0.83836\n",
      "Epoch: 22   Training loss: 0.210401   Validation Loss: 0.247818    Val_auc:0.83927\n",
      "Epoch: 23   Training loss: 0.209271   Validation Loss: 0.249760    Val_auc:0.83650\n",
      "Epoch: 24   Training loss: 0.208548   Validation Loss: 0.248781    Val_auc:0.83778\n",
      "Epoch: 25   Training loss: 0.208586   Validation Loss: 0.250044    Val_auc:0.83712\n",
      "Epoch: 26   Training loss: 0.206519   Validation Loss: 0.252473    Val_auc:0.83746\n",
      "Epoch: 27   Training loss: 0.206354   Validation Loss: 0.257889    Val_auc:0.83697\n",
      "Epoch: 28   Training loss: 0.206423   Validation Loss: 0.255608    Val_auc:0.83495\n",
      "Epoch: 29   Training loss: 0.205553   Validation Loss: 0.253898    Val_auc:0.83415\n",
      "Epoch: 30   Training loss: 0.205030   Validation Loss: 0.253138    Val_auc:0.83674\n",
      "Fold 2 metrics:   Avg Training loss: 0.2205   Avg Validation Loss: 0.2465   Val_auc:0.83674\n",
      "Saving test results for best model\n",
      "end of fold:  2 \n",
      "\n",
      "Fold number:  3\n",
      "Epoch: 1   Training loss: 0.261679   Validation Loss: 0.246340    Val_auc:0.84848\n",
      "Validation loss decresed from inf ----> 0.246340 Saving Model\n",
      "Epoch: 2   Training loss: 0.243538   Validation Loss: 0.242021    Val_auc:0.84924\n",
      "Validation loss decresed from 0.246340 ----> 0.242021 Saving Model\n",
      "Epoch: 3   Training loss: 0.238399   Validation Loss: 0.241904    Val_auc:0.84828\n",
      "Validation loss decresed from 0.242021 ----> 0.241904 Saving Model\n",
      "Epoch: 4   Training loss: 0.235873   Validation Loss: 0.242035    Val_auc:0.84813\n",
      "Epoch: 5   Training loss: 0.233228   Validation Loss: 0.248737    Val_auc:0.84760\n",
      "Epoch: 6   Training loss: 0.231780   Validation Loss: 0.242346    Val_auc:0.84726\n",
      "Epoch: 7   Training loss: 0.229430   Validation Loss: 0.242437    Val_auc:0.84721\n",
      "Epoch: 8   Training loss: 0.228111   Validation Loss: 0.243345    Val_auc:0.84718\n",
      "Epoch: 9   Training loss: 0.226697   Validation Loss: 0.244259    Val_auc:0.84599\n",
      "Epoch: 10   Training loss: 0.225536   Validation Loss: 0.244779    Val_auc:0.84563\n",
      "Epoch: 11   Training loss: 0.223590   Validation Loss: 0.245530    Val_auc:0.84538\n",
      "Epoch: 12   Training loss: 0.222146   Validation Loss: 0.246071    Val_auc:0.84570\n",
      "Epoch: 13   Training loss: 0.220880   Validation Loss: 0.247273    Val_auc:0.84157\n",
      "Epoch: 14   Training loss: 0.220003   Validation Loss: 0.248040    Val_auc:0.84131\n",
      "Epoch: 15   Training loss: 0.217844   Validation Loss: 0.251326    Val_auc:0.84260\n",
      "Epoch: 16   Training loss: 0.216424   Validation Loss: 0.248192    Val_auc:0.84243\n",
      "Epoch: 17   Training loss: 0.215689   Validation Loss: 0.250037    Val_auc:0.84188\n",
      "Epoch: 18   Training loss: 0.215317   Validation Loss: 0.249619    Val_auc:0.84076\n",
      "Epoch: 19   Training loss: 0.213763   Validation Loss: 0.250673    Val_auc:0.83948\n",
      "Epoch: 20   Training loss: 0.212848   Validation Loss: 0.250705    Val_auc:0.84173\n",
      "Epoch: 21   Training loss: 0.211584   Validation Loss: 0.252131    Val_auc:0.83649\n",
      "Epoch: 22   Training loss: 0.211340   Validation Loss: 0.251604    Val_auc:0.83865\n",
      "Epoch: 23   Training loss: 0.209710   Validation Loss: 0.252901    Val_auc:0.84040\n",
      "Epoch: 24   Training loss: 0.208921   Validation Loss: 0.255634    Val_auc:0.83593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25   Training loss: 0.208138   Validation Loss: 0.254823    Val_auc:0.83611\n",
      "Epoch: 26   Training loss: 0.208096   Validation Loss: 0.253999    Val_auc:0.83795\n",
      "Epoch: 27   Training loss: 0.207036   Validation Loss: 0.255410    Val_auc:0.83637\n",
      "Epoch: 28   Training loss: 0.205843   Validation Loss: 0.257687    Val_auc:0.83211\n",
      "Epoch: 29   Training loss: 0.205931   Validation Loss: 0.256008    Val_auc:0.83341\n",
      "Epoch: 30   Training loss: 0.205232   Validation Loss: 0.257169    Val_auc:0.83246\n",
      "Fold 3 metrics:   Avg Training loss: 0.2205   Avg Validation Loss: 0.2491   Val_auc:0.83246\n",
      "Saving test results for best model\n",
      "end of fold:  3 \n",
      "\n",
      "Fold number:  4\n",
      "Epoch: 1   Training loss: 0.262766   Validation Loss: 0.245623    Val_auc:0.84381\n",
      "Validation loss decresed from inf ----> 0.245623 Saving Model\n",
      "Epoch: 2   Training loss: 0.243006   Validation Loss: 0.244948    Val_auc:0.84457\n",
      "Validation loss decresed from 0.245623 ----> 0.244948 Saving Model\n",
      "Epoch: 3   Training loss: 0.237456   Validation Loss: 0.244296    Val_auc:0.84650\n",
      "Validation loss decresed from 0.244948 ----> 0.244296 Saving Model\n",
      "Epoch: 4   Training loss: 0.234043   Validation Loss: 0.250054    Val_auc:0.84521\n",
      "Epoch: 5   Training loss: 0.232313   Validation Loss: 0.244678    Val_auc:0.84528\n",
      "Epoch: 6   Training loss: 0.231357   Validation Loss: 0.257403    Val_auc:0.84526\n",
      "Epoch: 7   Training loss: 0.231840   Validation Loss: 0.244986    Val_auc:0.84476\n",
      "Epoch: 8   Training loss: 0.226535   Validation Loss: 0.246042    Val_auc:0.84294\n",
      "Epoch: 9   Training loss: 0.236473   Validation Loss: 0.260309    Val_auc:0.84073\n",
      "Epoch: 10   Training loss: 0.233221   Validation Loss: 0.252639    Val_auc:0.84263\n",
      "Epoch: 11   Training loss: 0.226397   Validation Loss: 0.250462    Val_auc:0.84175\n",
      "Epoch: 12   Training loss: 0.224761   Validation Loss: 0.248196    Val_auc:0.84199\n",
      "Epoch: 13   Training loss: 0.222046   Validation Loss: 0.251024    Val_auc:0.84339\n",
      "Epoch: 14   Training loss: 0.219696   Validation Loss: 0.249754    Val_auc:0.84150\n",
      "Epoch: 15   Training loss: 0.218084   Validation Loss: 0.251214    Val_auc:0.84020\n",
      "Epoch: 16   Training loss: 0.218324   Validation Loss: 0.257221    Val_auc:0.84079\n",
      "Epoch: 17   Training loss: 0.218298   Validation Loss: 0.253588    Val_auc:0.84074\n",
      "Epoch: 18   Training loss: 0.237703   Validation Loss: 0.268858    Val_auc:0.83624\n",
      "Epoch: 19   Training loss: 0.229849   Validation Loss: 0.251419    Val_auc:0.84152\n",
      "Epoch: 20   Training loss: 0.260632   Validation Loss: 0.262130    Val_auc:0.83795\n",
      "Epoch: 21   Training loss: 0.234794   Validation Loss: 0.250318    Val_auc:0.84194\n",
      "Epoch: 22   Training loss: 0.223875   Validation Loss: 0.253925    Val_auc:0.84344\n",
      "Epoch: 23   Training loss: 0.220569   Validation Loss: 0.256542    Val_auc:0.84272\n",
      "Epoch: 24   Training loss: 0.219680   Validation Loss: 0.251483    Val_auc:0.84321\n",
      "Epoch: 25   Training loss: 0.216870   Validation Loss: 0.251834    Val_auc:0.84360\n",
      "Epoch: 26   Training loss: 0.214975   Validation Loss: 0.254183    Val_auc:0.84348\n",
      "Epoch: 27   Training loss: 0.213374   Validation Loss: 0.254801    Val_auc:0.84226\n",
      "Epoch: 28   Training loss: 0.211592   Validation Loss: 0.254191    Val_auc:0.84358\n",
      "Epoch: 29   Training loss: 0.210697   Validation Loss: 0.254362    Val_auc:0.84307\n",
      "Epoch: 30   Training loss: 0.208695   Validation Loss: 0.255507    Val_auc:0.84279\n",
      "Fold 4 metrics:   Avg Training loss: 0.2273   Avg Validation Loss: 0.2524   Val_auc:0.84279\n",
      "Saving test results for best model\n",
      "end of fold:  4 \n",
      "\n",
      "Fold number:  5\n",
      "Epoch: 1   Training loss: 0.268793   Validation Loss: 0.248796    Val_auc:0.84770\n",
      "Validation loss decresed from inf ----> 0.248796 Saving Model\n",
      "Epoch: 2   Training loss: 0.247093   Validation Loss: 0.244908    Val_auc:0.84778\n",
      "Validation loss decresed from 0.248796 ----> 0.244908 Saving Model\n",
      "Epoch: 3   Training loss: 0.241238   Validation Loss: 0.246035    Val_auc:0.84862\n",
      "Epoch: 4   Training loss: 0.237444   Validation Loss: 0.246023    Val_auc:0.84816\n",
      "Epoch: 5   Training loss: 0.232555   Validation Loss: 0.243706    Val_auc:0.84862\n",
      "Validation loss decresed from 0.244908 ----> 0.243706 Saving Model\n",
      "Epoch: 6   Training loss: 0.231385   Validation Loss: 0.249308    Val_auc:0.84885\n",
      "Epoch: 7   Training loss: 0.233748   Validation Loss: 0.246171    Val_auc:0.84764\n",
      "Epoch: 8   Training loss: 0.230538   Validation Loss: 0.248296    Val_auc:0.84784\n",
      "Epoch: 9   Training loss: 0.228485   Validation Loss: 0.246183    Val_auc:0.84752\n",
      "Epoch: 10   Training loss: 0.225299   Validation Loss: 0.248321    Val_auc:0.84717\n",
      "Epoch: 11   Training loss: 0.224263   Validation Loss: 0.250473    Val_auc:0.84675\n",
      "Epoch: 12   Training loss: 0.222709   Validation Loss: 0.251933    Val_auc:0.84638\n",
      "Epoch: 13   Training loss: 0.221839   Validation Loss: 0.255942    Val_auc:0.84669\n",
      "Epoch: 14   Training loss: 0.219920   Validation Loss: 0.249093    Val_auc:0.84546\n",
      "Epoch: 15   Training loss: 0.218980   Validation Loss: 0.254571    Val_auc:0.84792\n",
      "Epoch: 16   Training loss: 0.220125   Validation Loss: 0.249729    Val_auc:0.84582\n",
      "Epoch: 17   Training loss: 0.217406   Validation Loss: 0.253038    Val_auc:0.84626\n",
      "Epoch: 18   Training loss: 0.215928   Validation Loss: 0.251428    Val_auc:0.84696\n",
      "Epoch: 19   Training loss: 0.214133   Validation Loss: 0.250401    Val_auc:0.84506\n",
      "Epoch: 20   Training loss: 0.224857   Validation Loss: 0.256836    Val_auc:0.84220\n",
      "Epoch: 21   Training loss: 0.216675   Validation Loss: 0.251885    Val_auc:0.84473\n",
      "Epoch: 22   Training loss: 0.212781   Validation Loss: 0.252024    Val_auc:0.84692\n",
      "Epoch: 23   Training loss: 0.210783   Validation Loss: 0.252974    Val_auc:0.84421\n",
      "Epoch: 24   Training loss: 0.210994   Validation Loss: 0.253502    Val_auc:0.84653\n",
      "Epoch: 25   Training loss: 0.211342   Validation Loss: 0.252606    Val_auc:0.84463\n",
      "Epoch: 26   Training loss: 0.208242   Validation Loss: 0.255047    Val_auc:0.84375\n",
      "Epoch: 27   Training loss: 0.208111   Validation Loss: 0.255138    Val_auc:0.84242\n",
      "Epoch: 28   Training loss: 0.207101   Validation Loss: 0.255484    Val_auc:0.84278\n",
      "Epoch: 29   Training loss: 0.206298   Validation Loss: 0.255797    Val_auc:0.84264\n",
      "Epoch: 30   Training loss: 0.206124   Validation Loss: 0.259759    Val_auc:0.84306\n",
      "Fold 5 metrics:   Avg Training loss: 0.2225   Avg Validation Loss: 0.2512   Val_auc:0.84306\n",
      "Saving test results for best model\n",
      "end of fold:  5 \n",
      "\n",
      "Wall time: 15min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "n_epochs = 30\n",
    "\n",
    "test_x = torch.from_numpy(df_test[train_cols].values).float()#.cuda()\n",
    "test_dataset = torch.utils.data.TensorDataset(test_x)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(df_train, y_train)):\n",
    "    running_train_loss, running_val_loss = [],[]\n",
    "    val_loss_min = np.Inf\n",
    "#     print(i, train_idx.shape, val_idx.shape)\n",
    "\n",
    "    print(\"Fold number: \", n_fold+1)\n",
    "    train_x_fold = torch.from_numpy(df_train.iloc[train_idx][train_cols].values).float().cuda()\n",
    "    train_y_fold = torch.from_numpy(y_train[train_idx].values).float().cuda()\n",
    "    train_fold_dataset = torch.utils.data.TensorDataset(train_x_fold,train_y_fold)\n",
    "    trainloader = torch.utils.data.DataLoader(train_fold_dataset, batch_size = batch_size, shuffle = True)\n",
    "    \n",
    "    val_x_fold = torch.from_numpy(df_train.iloc[val_idx][train_cols].values).float().cuda()\n",
    "    val_y_fold = torch.from_numpy(y_train[val_idx].values).float().cuda()\n",
    "    val_fold_dataset = torch.utils.data.TensorDataset(val_x_fold,val_y_fold )\n",
    "    valloader = torch.utils.data.DataLoader(val_fold_dataset, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "    #Initiating model\n",
    "    model = classifier(100)\n",
    "    model.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.005)\n",
    "    # criterion = nn.CrossEntropyLoss() # also number of outputs should be 2\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0\n",
    "        \n",
    "        for train_x_batch, train_y_batch in trainloader:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_x_batch)\n",
    "            loss = criterion(output, train_y_batch.view(-1,1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()/len(trainloader)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            model.eval()\n",
    "            val_preds = []\n",
    "            val_true = []\n",
    "            \n",
    "            for i, (val_x_batch, val_y_batch) in enumerate(valloader):\n",
    "                val_output = model(val_x_batch)\n",
    "                val_loss += (criterion(val_output, val_y_batch.view(-1,1)).item())/len(valloader)\n",
    "                batch_output = sigmoid(val_output.cpu().numpy().squeeze())\n",
    "                try:\n",
    "                    batch_output = list(batch_output)\n",
    "                except TypeError:\n",
    "                    batch_output =[batch_output]\n",
    "                val_preds.extend(batch_output)\n",
    "                \n",
    "#                 batch_true = val_y_batch.cpu().numpy().squeeze()\n",
    "#                 try:\n",
    "#                     batch_true = list(batch_true)\n",
    "#                 except TypeError:\n",
    "#                     batch_true =[batch_true]\n",
    "#                 val_true.extend(batch_true)\n",
    "                \n",
    "        running_train_loss.append(train_loss)\n",
    "        running_val_loss.append(val_loss)\n",
    "        \n",
    "        \n",
    "        print(\"Epoch: {}   Training loss: {:.6f}   Validation Loss: {:.6f}    Val_auc:{:.5f}\".format(epoch+1,\n",
    "                                                                              train_loss,\n",
    "                                                                               val_loss,\n",
    "                                                                               roc_auc_score(y_train[val_idx].values,\n",
    "                                                                                             val_preds))\n",
    "         )\n",
    "        \n",
    "        if val_loss <= val_loss_min:\n",
    "            print(\"Validation loss decresed from {:.6f} ----> {:.6f} Saving Model\".format(val_loss_min,val_loss))\n",
    "            torch.save(model.state_dict(), \"san_cust_tran_torch.pt\")\n",
    "            val_loss_min = val_loss\n",
    "            \n",
    "        \n",
    "    oof[val_idx] = val_preds    \n",
    "    print(\"Fold {} metrics:   Avg Training loss: {:.4f}   Avg Validation Loss: {:.4f}   Val_auc:{:.5f}\".format(n_fold+1,\n",
    "                                                                              np.mean(running_train_loss),\n",
    "                                                                               np.mean(running_val_loss),\n",
    "                                                                               roc_auc_score(y_train[val_idx].values,\n",
    "                                                                                             oof[val_idx])))\n",
    "    y_test_pred_fold = []\n",
    "    print(\"Saving test results for best model\")\n",
    "    for (test_x_batch,) in testloader:\n",
    "        model.load_state_dict(torch.load(\"san_cust_tran_torch.pt\"))\n",
    "        model.cpu()\n",
    "        test_output = model(test_x_batch)\n",
    "        test_batch_output = sigmoid(test_output.detach().numpy().squeeze())\n",
    "        try:\n",
    "            test_batch_output = list(test_batch_output)\n",
    "        except TypeError:\n",
    "            test_batch_output =[test_batch_output]\n",
    "        y_test_pred_fold.extend(test_batch_output)\n",
    "    predictions += np.array(y_test_pred_fold)/folds.n_splits \n",
    "    \n",
    "    print(\"end of fold: \",n_fold+1,\"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plt.title(\"Train vs val loss on last epoch\")\n",
    "plt.plot(running_train_loss, label = \"train\")\n",
    "plt.plot(running_val_loss, label = \"val\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'ID_code': df_test.ID_code.values,\n",
    "                   'target': predictions})\n",
    "sub.to_csv('sub_pytorch_simplenn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[np.arange(0,10)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-0.0652, -0.1257, -0.3529,  ..., -0.0391,  0.2176, -0.1040],\n",
       "                      [-0.0255, -0.3264, -0.1005,  ...,  0.1810,  0.1328, -0.1319],\n",
       "                      [-0.2172, -0.2330, -0.2230,  ...,  0.1334, -0.0833, -0.0727],\n",
       "                      ...,\n",
       "                      [-0.3240, -0.1038, -0.3555,  ..., -0.0988,  0.0431, -0.3935],\n",
       "                      [-0.1193, -0.0127, -0.0562,  ...,  0.0815,  0.0255, -0.1399],\n",
       "                      [-0.1967, -0.1648, -0.1256,  ...,  0.3448, -0.1251, -0.2353]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.2211, -0.1639,  0.0224, -0.2023,  0.0124, -0.1206, -0.1440, -0.2307,\n",
       "                       0.1026, -0.1597,  0.1066,  0.0243, -0.6924,  0.1618, -0.2068, -0.0942,\n",
       "                       0.0198, -0.0583,  0.1105,  0.0042,  0.1912,  0.0457,  0.0496,  0.0537,\n",
       "                       0.0404,  0.1532,  0.2986, -0.0159, -0.1630, -0.0023,  0.0543,  0.0579,\n",
       "                      -0.1685,  0.0911,  0.2816,  0.0360, -0.2756,  0.0850, -0.2084,  0.0841,\n",
       "                      -0.0658,  0.0556,  0.1181, -0.0570,  0.1520, -0.0720, -0.2186,  0.0258,\n",
       "                       0.0776,  0.1027, -0.0589, -0.1130,  0.1896,  0.0328, -0.4019,  0.0261,\n",
       "                       0.0817,  0.3004,  0.2027, -0.2699, -0.2552,  0.1272,  0.2042, -0.0661,\n",
       "                       0.0978, -0.0275,  0.1953,  0.0697, -0.0288, -0.0201, -0.2648, -0.0588,\n",
       "                       0.0999,  0.1355,  0.1100,  0.0132,  0.0679, -0.1136,  0.0345,  0.1708,\n",
       "                      -0.0363, -0.1513, -0.0188, -0.1362, -0.1003, -0.0300,  0.0618, -0.7219,\n",
       "                       0.0620, -0.2331,  0.0359,  0.0228, -0.0354, -0.2474, -0.1578, -0.0336,\n",
       "                       0.0549, -0.0373, -0.0770, -0.1512], device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.1024,  0.0510,  0.1328,  ...,  0.0793,  0.1247,  0.0654],\n",
       "                      [ 0.0490,  0.1042, -0.0324,  ...,  0.1853,  0.0827,  0.1671],\n",
       "                      [ 0.0475,  0.0278, -0.1452,  ..., -0.0800, -0.1304, -0.0867],\n",
       "                      ...,\n",
       "                      [ 0.0608,  0.1631,  0.0939,  ...,  0.0756,  0.0401,  0.1890],\n",
       "                      [ 0.0253, -0.1895, -0.0651,  ...,  0.0587, -0.0954, -0.1588],\n",
       "                      [ 0.0408,  0.0410, -0.0580,  ...,  0.0868,  0.0280,  0.0392]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0363,  0.1272, -0.0856, -0.0327, -0.0948,  0.7851,  1.0952,  0.1437,\n",
       "                      -0.0572, -0.3034,  0.1534,  0.3754,  0.1722,  0.6218,  0.0835, -0.2487,\n",
       "                      -0.1322,  0.2597,  1.0360,  0.7738,  0.0064,  0.2004,  0.1142,  0.1467,\n",
       "                      -0.1185,  0.0805, -0.0396,  0.1827,  0.1009,  0.1213,  0.0660, -0.0352,\n",
       "                      -0.1462, -0.1486, -0.0137, -0.0920, -0.1105,  0.9389,  0.2354,  0.1214,\n",
       "                      -0.0992,  0.0929, -0.0860,  0.1894, -0.0651, -0.2637,  1.1796,  0.0632,\n",
       "                       0.0125, -0.1716,  0.4705,  0.0427,  0.1332,  0.0939,  0.1284,  0.7005,\n",
       "                       0.1050, -0.1592,  0.2212,  0.1475, -0.3243,  0.1762,  0.1195, -0.0269,\n",
       "                       0.2567,  0.1127,  0.4774,  0.0730,  0.0503,  0.1804,  0.1107,  0.4214,\n",
       "                      -0.1291,  0.8826,  0.2748, -0.0399, -0.0919,  0.1631,  0.1054,  1.1404,\n",
       "                       0.9225, -0.0304, -0.1196,  0.5942,  0.0898, -0.1013,  0.9705,  1.1872,\n",
       "                       0.1302,  0.1685, -0.3345,  0.1752,  0.1393,  0.4277, -0.0927,  0.1124,\n",
       "                      -0.1864,  0.1082, -0.1084,  0.1207], device='cuda:0')),\n",
       "             ('fc3.weight',\n",
       "              tensor([[-0.0248, -0.0253,  0.0172,  0.1856,  0.0150,  0.2358,  0.2436,  0.1155,\n",
       "                       -0.0166,  0.0048, -0.0264,  0.1267, -0.0175,  0.2094,  0.1914,  0.0649,\n",
       "                       -0.0118,  0.0583,  0.3151,  0.2213, -0.0242, -0.0156, -0.0116, -0.0278,\n",
       "                       -0.0217, -0.0222, -0.0266,  0.1101, -0.0274, -0.0056, -0.0108,  0.0099,\n",
       "                       -0.0044, -0.0200,  0.0288, -0.0256,  0.0043,  0.1616, -0.0082, -0.0293,\n",
       "                        0.0761, -0.0330,  0.0872, -0.0186, -0.0426,  0.0745,  0.2083, -0.0204,\n",
       "                        0.0843,  0.1004,  0.3081, -0.0226, -0.0165, -0.0156, -0.0174,  0.1648,\n",
       "                       -0.0108, -0.0239, -0.0215, -0.0159, -0.0312, -0.0326, -0.0036,  0.0969,\n",
       "                        0.1104, -0.0347,  0.1187, -0.0245,  0.0187, -0.0159, -0.0132,  0.1770,\n",
       "                        0.0291,  0.2427,  0.1385, -0.0114,  0.0703,  0.1358, -0.0148,  0.3612,\n",
       "                        0.2583,  0.0775,  0.0884,  0.2218, -0.0442,  0.1009,  0.3392,  0.3024,\n",
       "                       -0.0217, -0.0122,  0.0658, -0.0279,  0.0819,  0.1188,  0.1227, -0.0299,\n",
       "                       -0.0220, -0.0080,  0.0049, -0.0128]], device='cuda:0')),\n",
       "             ('fc3.bias', tensor([-0.8120], device='cuda:0'))])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1000, 200]) torch.Size([1000])\n",
      "1 torch.Size([1000, 200]) torch.Size([1000])\n",
      "2 torch.Size([1000, 200]) torch.Size([1000])\n",
      "3 torch.Size([1000, 200]) torch.Size([1000])\n",
      "4 torch.Size([1000, 200]) torch.Size([1000])\n",
      "5 torch.Size([1, 200]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for i, (val_x_batch, val_y_batch) in enumerate(valloader):\n",
    "    print(i, val_x_batch.shape, val_y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49217793], dtype=float32)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(val_output.cpu().numpy()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "print(a)\n",
    "b = np.arange(2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1])]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
